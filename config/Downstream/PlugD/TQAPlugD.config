[train] #train parameters
epoch = 10
batch_size = 1

shuffle = True
no_valid = False
valid_mode = batch
reader_num = 1

optimizer = AdamW
learning_rate = 1e-4
weight_decay = 1e-5
grad_accumulate = 10

warmup_steps=200
training_steps=5000
max_grad_norm=2.0

scheduler=linear

inspector_para=*plug*

max_len = 16
ctx_len = 32
ans_max_len = 16

layerth = 4
bottleneck_dim=8


[eval] #eval parameters
batch_size = 1
reader_num = 4

[data] #data parameters
train_dataset_type = OpenQA
train_formatter_type = OpenQAPlugD
train_data_path = data/dpr-top5/triviaqa-train-kilt.jsonl

valid_dataset_type = OpenQA
valid_formatter_type = OpenQAPlugD
valid_data_path = data/dpr-top5/triviaqa-dev-kilt.jsonl


[model] #model parameters
model_name = Seq2Seq
pretrained_model = llama

model_type = PlugD

[output] #output parameters
output_time = 20
test_time = 1
output_grad_step = 20

model_name = TQAPlugD
output_function = squad

output_grad = False